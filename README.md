# Image Fusion
## Multi-modal image fusion
### Infrared and visible image fusion
<table>
<thead>
  <tr>
    <th>方法</th>
    <th>标题</th>
    <th>代码</th>
    <th>基础框架</th>
    <th>监督范式</th>
    <th>发表期刊或会议</th>
    <th>年份</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>DenseFuse</td>
    <td>DenseFuse: A Fusion Approach to Infrared and Visible Images</td>
    <td>Code</td>
    <td>AE</td>
    <td>自监督</td>
    <td>TIP</td>
    <td>2019</td>
  </tr>
  <tr>
    <td>FusionGAN</td>
    <td>FusionGAN: A generative adversarial network for infrared and&nbsp;&nbsp;&nbsp;visible image fusion</td>
    <td>Code</td>
    <td>GAN</td>
    <td>无监督</td>
    <td>IF</td>
    <td>2019</td>
  </tr>
  <tr>
    <td>DDcGAN</td>
    <td>Learning a Generative Model for Fusing Infrared and Visible&nbsp;&nbsp;&nbsp;Images via Conditional Generative Adversarial Network with Dual&nbsp;&nbsp;&nbsp;Discriminators</td>
    <td>Code</td>
    <td>GAN</td>
    <td>无监督</td>
    <td>IJCAI</td>
    <td>2019</td>
  </tr>
  <tr>
    <td>NestFuse</td>
    <td>NestFuse: An Infrared and Visible Image Fusion Architecture&nbsp;&nbsp;&nbsp;Based on Nest Connection and Spatial/Channel Attention Models</td>
    <td>Code</td>
    <td>AE</td>
    <td>自监督</td>
    <td>TIM</td>
    <td>2020</td>
  </tr>
  <tr>
    <td>DDcGAN</td>
    <td>DDcGAN: A dual-discriminator conditional generative&nbsp;&nbsp;&nbsp;adversarial network for multi-resolution image fusion</td>
    <td>Code</td>
    <td>GAN</td>
    <td>无监督</td>
    <td>TIP </td>
    <td>2020</td>
  </tr>
  <tr>
    <td>RFN-Nest</td>
    <td>RFN-Nest: An end-to-end residual fusion network for infrared&nbsp;&nbsp;&nbsp;and visible images</td>
    <td>Code</td>
    <td>AE</td>
    <td>自监督</td>
    <td>IF</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>CSF</td>
    <td>Classification Saliency-Based Rule for Visible and Infrared&nbsp;&nbsp;&nbsp;Image Fusion</td>
    <td>Code</td>
    <td>AE</td>
    <td>自监督</td>
    <td>TCI</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>DRF</td>
    <td>DRF: Disentangled Representation for Visible and Infrared&nbsp;&nbsp;&nbsp;Image Fusion</td>
    <td>Code</td>
    <td>AE</td>
    <td>自监督</td>
    <td>TIM</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>SEDRFuse</td>
    <td>SEDRFuse: A Symmetric Encoder–Decoder With Residual Block&nbsp;&nbsp;&nbsp;Network for Infrared and Visible Image Fusion</td>
    <td>Code</td>
    <td>AE</td>
    <td>自监督</td>
    <td>TIM</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>EAGIF</td>
    <td>Learning a Deep Multi-Scale Feature Ensemble and an&nbsp;&nbsp;&nbsp;Edge-Attention Guidance for Image Fusion</td>
    <td>Code</td>
    <td>AE</td>
    <td>自监督</td>
    <td>TCSVT</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>Meta-Learning</td>
    <td> Different Input&nbsp;&nbsp;&nbsp;Resolutions and Arbitrary Output Resolution: A Meta Learning-Based Deep&nbsp;&nbsp;&nbsp;Framework for Infrared and Visible Image Fusion</td>
    <td>Code</td>
    <td>CNN</td>
    <td>无监督</td>
    <td>TIP</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>RXDNFuse</td>
    <td>RXDNFuse: A aggregated residual dense network for infrared and&nbsp;&nbsp;&nbsp;visible image fusion</td>
    <td>Code</td>
    <td>CNN</td>
    <td>无监督</td>
    <td>IF</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>STDFusionNet</td>
    <td>STDFusionNet: An Infrared and Visible Image Fusion Network&nbsp;&nbsp;&nbsp;Based on Salient Target Detection</td>
    <td>Code</td>
    <td>CNN</td>
    <td>无监督</td>
    <td>TIM</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>D2LE</td>
    <td>A Bilevel Integrated Model With Data-Driven Layer Ensemble for&nbsp;&nbsp;&nbsp;Multi-Modality Image Fusion</td>
    <td>Code</td>
    <td>CNN</td>
    <td>无监督</td>
    <td>TIP</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>HAF</td>
    <td>Searching a Hierarchically Aggregated Fusion Architecture for&nbsp;&nbsp;&nbsp;Fast Multi-Modality Image Fusion</td>
    <td>Code</td>
    <td>CNN</td>
    <td>无监督</td>
    <td>ACM MM</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>SDDGAN</td>
    <td>Semantic-supervised Infrared and Visible Image Fusion via a&nbsp;&nbsp;&nbsp;Dual-discriminator Generative Adversarial Network</td>
    <td>Code</td>
    <td>GAN</td>
    <td>无监督</td>
    <td>TMM</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>Detail-GAN</td>
    <td>Infrared and visible image fusion via detail preserving&nbsp;&nbsp;&nbsp;adversarial learning</td>
    <td>Code</td>
    <td>GAN</td>
    <td>无监督</td>
    <td>IF</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>Perception-GAN</td>
    <td> Image fusion based on&nbsp;&nbsp;&nbsp;generative adversarial network consistent with perception</td>
    <td>Code</td>
    <td>GAN</td>
    <td>无监督</td>
    <td>IF</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>GAN-FM</td>
    <td>GAN-FM: Infrared and Visible&nbsp;&nbsp;&nbsp;Image Fusion Using GAN With Full-Scale Skip Connection and Dual Markovian&nbsp;&nbsp;&nbsp;Discriminators</td>
    <td>Code</td>
    <td>GAN</td>
    <td>无监督</td>
    <td>TCI</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>AttentionFGAN</td>
    <td>AttentionFGAN: Infrared and Visible Image Fusion Using&nbsp;&nbsp;&nbsp;Attention-Based Generative Adversarial Networks</td>
    <td>Code</td>
    <td>GAN</td>
    <td>无监督</td>
    <td>TMM</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>GANMcC</td>
    <td>GANMcC: A Generative&nbsp;&nbsp;&nbsp;Adversarial Network With Multiclassification Constraints for Infrared and&nbsp;&nbsp;&nbsp;Visible Image Fusion</td>
    <td>Code</td>
    <td>GAN</td>
    <td>无监督</td>
    <td>TIM</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>MgAN-Fuse</td>
    <td>Multigrained Attention Network for Infrared and Visible Image&nbsp;&nbsp;&nbsp;Fusion</td>
    <td>Code</td>
    <td>GAN</td>
    <td>无监督</td>
    <td>TIM</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>TC-GAN</td>
    <td>Infrared and Visible Image&nbsp;&nbsp;&nbsp;Fusion via Texture Conditional Generative Adversarial Network</td>
    <td>Code</td>
    <td>GAN</td>
    <td>无监督</td>
    <td>TCSVT</td>
    <td>2021</td>
  </tr>
  <tr>
    <td>SeAFusion</td>
    <td>Image fusion in the loop of&nbsp;&nbsp;&nbsp;high-level vision tasks: A semantic-aware real-time infrared and visible&nbsp;&nbsp;&nbsp;image fusion network</td>
    <td>Code</td>
    <td>CNN</td>
    <td>无监督</td>
    <td>IF</td>
    <td>2022</td>
  </tr>
  <tr>
    <td>PIAFusion</td>
    <td>PIAFusion: A progressive infrared and visible image fusion&nbsp;&nbsp;&nbsp;network based on illumination aware</td>
    <td>Code</td>
    <td>CNN</td>
    <td>无监督</td>
    <td>IF</td>
    <td>2022</td>
  </tr>
</tbody>
</table>
[Code](https://github.com/LiuzhuForFun/Hierarchical-NAS-Image-Fusion)

### Medical image fusion
